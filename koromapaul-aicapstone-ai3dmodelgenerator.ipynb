{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8265873,"sourceType":"datasetVersion","datasetId":4906907}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T05:32:35.657003Z","iopub.execute_input":"2025-07-02T05:32:35.657233Z","iopub.status.idle":"2025-07-02T05:32:48.345103Z","shell.execute_reply.started":"2025-07-02T05:32:35.657217Z","shell.execute_reply":"2025-07-02T05:32:48.344305Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nCollecting gradio\n  Downloading gradio-5.35.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.10.4 (from gradio)\n  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nDownloading gradio-5.35.0-py3-none-any.whl (54.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.10.4-py3-none-any.whl (323 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\nDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\nSuccessfully installed fastapi-0.115.14 ffmpy-0.6.0 gradio-5.35.0 gradio-client-1.10.4 groovy-0.1.2 python-multipart-0.0.20 ruff-0.12.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.3 uvicorn-0.35.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# AI 3D Model Generator Capstone Project\n\n# Import Libraries\nimport json\nimport os\nfrom scipy.io import loadmat\nimport numpy as np\nimport cv2\nfrom scipy.ndimage import zoom\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, Reshape, Input\nfrom tensorflow.keras.utils import Sequence\nimport matplotlib.pyplot as plt\nfrom skimage.measure import marching_cubes\nfrom scipy.ndimage import gaussian_filter\nimport tempfile\nimport gradio as gr\n\n# Load Pix3D Annotations\ndef load_pix3d_annotations(base_dir, json_filename='pix3d.json'):\n    json_path = os.path.join(base_dir, json_filename)\n    if not os.path.exists(json_path):\n        raise FileNotFoundError(f\"JSON file '{json_path}' not found.\")\n    with open(json_path, 'r') as f:\n        pix3d_data = json.load(f)\n\n    valid_samples = []\n    for item in pix3d_data:\n        if item['img'] and item['model'] and item.get('voxel'):\n            valid_samples.append({\n                'image_path': os.path.join(base_dir, item['img']),\n                'voxel_path': os.path.join(base_dir, item['voxel']),\n                'model_path': os.path.join(base_dir, item['model'])\n            })\n\n    print(f\"Found {len(valid_samples)} valid samples.\")\n    return valid_samples\n\n# Dataset Path\ndataset_path = '/kaggle/input/pix3d-dataset'\nsamples = load_pix3d_annotations(dataset_path)\n\n# Train Test Split\ntrain_samples, val_samples = train_test_split(samples, test_size=0.2, random_state=42)\n\n# Extract Point Cloud from Voxel\ndef extract_point_cloud_from_voxel(voxel_grid, threshold=0.5):\n    points = np.argwhere(voxel_grid.squeeze() > threshold)\n    return points\n\n# Data Generator\nclass Pix3DPointCloudGenerator(Sequence):\n    def __init__(self, samples, batch_size=8, image_size=64, num_points=2048, shuffle=True):\n        self.samples = samples\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.num_points = num_points\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.samples) / self.batch_size))\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.samples))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __getitem__(self, index):\n        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_samples = [self.samples[k] for k in indexes]\n\n        x, y = self.__data_generation(batch_samples)\n        return np.array(x), np.array(y)\n\n    def __data_generation(self, batch_samples):\n        x = []\n        y = []\n        for sample in batch_samples:\n            try:\n                image = cv2.imread(sample['image_path'])\n                if image is None:\n                    continue\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, (self.image_size, self.image_size))\n                image = image / 255.0\n\n                voxel_data = loadmat(sample['voxel_path'])\n                if 'voxel' in voxel_data:\n                    voxel = voxel_data['voxel']\n                elif 'model' in voxel_data:\n                    voxel = voxel_data['model']\n                else:\n                    continue\n                if voxel.ndim != 3:\n                    continue\n                voxel = voxel.astype('float32')\n\n                scale_factor = 32 / voxel.shape[0]\n                voxel = zoom(voxel, (scale_factor, scale_factor, scale_factor), order=0)\n\n                points = extract_point_cloud_from_voxel(voxel)\n                if len(points) >= self.num_points:\n                    selected_idx = np.random.choice(len(points), self.num_points, replace=False)\n                    points = points[selected_idx]\n                else:\n                    pad_size = self.num_points - len(points)\n                    pad_points = np.zeros((pad_size, 3))\n                    points = np.vstack((points, pad_points))\n\n                x.append(image)\n                y.append(points)\n\n            except Exception as e:\n                print(f\"Error loading {sample['voxel_path']} -> {e}\")\n                continue\n\n        return x, y\n\n# Build PointCloudNet Model\ndef pointcloudnet_build(image_size=64, num_points=2048):\n    model = Sequential()\n    model.add(Input(shape=(image_size, image_size, 3)))\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n    model.add(Flatten())\n    model.add(Dense(num_points * 3, activation='linear'))\n    model.add(Reshape((num_points, 3)))\n\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\n# Build Generators\ntrain_generator = Pix3DPointCloudGenerator(train_samples, batch_size=8, image_size=64, num_points=2048)\nval_generator = Pix3DPointCloudGenerator(val_samples, batch_size=8, image_size=64, num_points=2048)\n\n# Build and Train Model\nmodel = pointcloudnet_build()\nmodel.fit(train_generator, validation_data=val_generator, epochs=20)\nmodel.save('pointcloudnet_model.h5')\n\nprint(\"Model Training completed and saved.\")\n\n# Mesh Generation from Point Cloud\ndef generate_mesh_from_pointcloud(points, grid_size=64):\n    voxel_grid = np.zeros((grid_size, grid_size, grid_size))\n    for point in points:\n        x, y, z = np.clip(point.astype(int), 0, grid_size - 1)\n        voxel_grid[x, y, z] = 1.0\n\n    voxel_grid = gaussian_filter(voxel_grid, sigma=1)\n    verts, faces, normals, _ = marching_cubes(voxel_grid, level=0.5)\n    return verts, faces\n\n# Export Mesh to OBJ\ndef export_mesh_as_obj(vertices, faces, obj_filename='generated_mesh.obj'):\n    with open(obj_filename, 'w') as f:\n        for v in vertices:\n            f.write(f\"v {v[0]} {v[1]} {v[2]}\\n\")\n        for face in faces:\n            f.write(f\"f {int(face[0])+1} {int(face[1])+1} {int(face[2])+1}\\n\")\n    print(f\"Exported mesh to {obj_filename}\")\n\n# Gradio Prediction Function\ndef predict_mesh(image_input):\n    try:\n        image = cv2.resize(image_input, (64, 64))\n        image = image / 255.0\n        image = np.expand_dims(image, axis=0)\n\n        point_cloud = model.predict(image)[0]\n        verts, faces = generate_mesh_from_pointcloud(point_cloud)\n\n        temp_dir = tempfile.mkdtemp()\n        obj_path = os.path.join(temp_dir, 'generated_mesh.obj')\n        export_mesh_as_obj(verts, faces, obj_filename=obj_path)\n\n        fig = plt.figure(figsize=(8, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        ax.plot_trisurf(verts[:, 0], verts[:, 1], faces, verts[:, 2], color='lightblue', edgecolor='gray')\n        ax.set_xlabel('X')\n        ax.set_ylabel('Y')\n        ax.set_zlabel('Z')\n        plt.tight_layout()\n        plt.close(fig)\n\n        return fig, obj_path\n\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None, None\n\n# Gradio Interface\niface = gr.Interface(\n    fn=predict_mesh,\n    inputs=gr.Image(type='numpy', label=\"Upload 2D Image\"),\n    outputs=[\n        gr.Plot(label=\"Predicted 3D Mesh Visualization\"),\n        gr.File(label=\"Download 3D .obj Model\")\n    ],\n    title=\"AI 3D Model Generator\",\n    description=\"Upload an image to convert to a 3D mesh model and export as .obj\",\n    live=True\n)\n\niface.launch()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T05:33:05.577191Z","iopub.execute_input":"2025-07-02T05:33:05.577464Z","iopub.status.idle":"2025-07-02T07:10:09.165850Z","shell.execute_reply.started":"2025-07-02T05:33:05.577436Z","shell.execute_reply":"2025-07-02T07:10:09.165081Z"}},"outputs":[{"name":"stderr","text":"2025-07-02 05:33:09.679595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751434390.044541      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751434390.147232      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 10069 valid samples.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751434413.955316      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1751434413.956184      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751434420.102820     109 service.cc:148] XLA service 0x7cb0c40103f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1751434420.104447     109 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1751434420.104469     109 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1751434420.464296     109 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/1006\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:08\u001b[0m 7s/step - loss: 181.3199 - mae: 9.5459","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751434423.686914     109 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  89/1006\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:08\u001b[0m 402ms/step - loss: 105.1335 - mae: 8.3118","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 266/1006\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:25\u001b[0m 359ms/step - loss: 95.1545 - mae: 8.0850","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 778/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 342ms/step - loss: 88.5163 - mae: 7.9099","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 426ms/step - loss: 87.1987 - mae: 7.8702 - val_loss: 77.6702 - val_mae: 7.4495\nEpoch 2/20\n\u001b[1m 680/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 214ms/step - loss: 78.4544 - mae: 7.4804","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 714/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 214ms/step - loss: 78.4220 - mae: 7.4784","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 959/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - loss: 78.1750 - mae: 7.4619","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 269ms/step - loss: 78.1299 - mae: 7.4589 - val_loss: 76.4092 - val_mae: 7.2662\nEpoch 3/20\n\u001b[1m 451/1006\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 218ms/step - loss: 75.9276 - mae: 7.2890","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 744/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 212ms/step - loss: 75.8440 - mae: 7.2840","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 893/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 213ms/step - loss: 75.8180 - mae: 7.2821","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 264ms/step - loss: 75.7850 - mae: 7.2799 - val_loss: 76.2054 - val_mae: 7.1269\nEpoch 4/20\n\u001b[1m 594/1006\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 425ms/step - loss: 73.7264 - mae: 7.1180","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 917/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m35s\u001b[0m 402ms/step - loss: 73.5091 - mae: 7.1067","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 992/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 400ms/step - loss: 73.4655 - mae: 7.1040","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 500ms/step - loss: 73.4582 - mae: 7.1035 - val_loss: 75.4080 - val_mae: 7.0169\nEpoch 5/20\n\u001b[1m  42/1006\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:29\u001b[0m 279ms/step - loss: 75.3061 - mae: 7.1646","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\nlibpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 398/1006\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 240ms/step - loss: 71.5169 - mae: 6.9859","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 286ms/step - loss: 70.5743 - mae: 6.9125 - val_loss: 75.4156 - val_mae: 7.2290\nEpoch 6/20\n\u001b[1m  42/1006\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 223ms/step - loss: 66.5034 - mae: 6.7567","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 196/1006\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 225ms/step - loss: 66.3522 - mae: 6.6597","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 391/1006\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 223ms/step - loss: 66.0947 - mae: 6.6238","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 275ms/step - loss: 66.0767 - mae: 6.6042 - val_loss: 74.8569 - val_mae: 7.1572\nEpoch 7/20\n\u001b[1m 344/1006\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 215ms/step - loss: 60.1911 - mae: 6.2280","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 601/1006\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 215ms/step - loss: 60.7150 - mae: 6.2542","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 643/1006\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 215ms/step - loss: 60.7835 - mae: 6.2579","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 267ms/step - loss: 61.1492 - mae: 6.2783 - val_loss: 75.2837 - val_mae: 7.0738\nEpoch 8/20\n\u001b[1m 277/1006\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 221ms/step - loss: 56.2164 - mae: 5.9485","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 394/1006\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 227ms/step - loss: 56.4067 - mae: 5.9629","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1003/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 56.6199 - mae: 5.9824","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 280ms/step - loss: 56.6210 - mae: 5.9824 - val_loss: 75.2783 - val_mae: 7.0061\nEpoch 9/20\n\u001b[1m 122/1006\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:16\u001b[0m 222ms/step - loss: 50.0841 - mae: 5.5365","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 339/1006\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 215ms/step - loss: 49.8885 - mae: 5.5346","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 823/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m38s\u001b[0m 212ms/step - loss: 50.3567 - mae: 5.5719","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 264ms/step - loss: 50.5819 - mae: 5.5866 - val_loss: 77.3330 - val_mae: 6.9616\nEpoch 10/20\n\u001b[1m 263/1006\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 217ms/step - loss: 44.7826 - mae: 5.1957","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 365/1006\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 215ms/step - loss: 44.9255 - mae: 5.2058","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 736/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 215ms/step - loss: 45.3274 - mae: 5.2329","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 266ms/step - loss: 45.6696 - mae: 5.2547 - val_loss: 78.2897 - val_mae: 7.0605\nEpoch 11/20\n\u001b[1m  60/1006\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:20\u001b[0m 276ms/step - loss: 39.6719 - mae: 4.8238","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 302/1006\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 222ms/step - loss: 40.8781 - mae: 4.9106","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 331/1006\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 221ms/step - loss: 40.9249 - mae: 4.9134","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 269ms/step - loss: 41.8596 - mae: 4.9737 - val_loss: 81.7544 - val_mae: 7.1751\nEpoch 12/20\n\u001b[1m 296/1006\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 223ms/step - loss: 37.7123 - mae: 4.6381","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 330/1006\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 220ms/step - loss: 37.7586 - mae: 4.6426","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 912/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m21s\u001b[0m 225ms/step - loss: 38.7944 - mae: 4.7165","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 277ms/step - loss: 38.8853 - mae: 4.7237 - val_loss: 81.9817 - val_mae: 7.2044\nEpoch 13/20\n\u001b[1m  27/1006\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 238ms/step - loss: 31.7423 - mae: 4.1702","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 156/1006\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 217ms/step - loss: 35.5126 - mae: 4.4522","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 975/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 36.9174 - mae: 4.5634","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 265ms/step - loss: 36.9247 - mae: 4.5640 - val_loss: 82.9154 - val_mae: 7.2321\nEpoch 14/20\n\u001b[1m 298/1006\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 223ms/step - loss: 35.2322 - mae: 4.3774","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 787/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m48s\u001b[0m 223ms/step - loss: 34.8018 - mae: 4.3690","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 803/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 222ms/step - loss: 34.7966 - mae: 4.3691","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 273ms/step - loss: 34.7692 - mae: 4.3725 - val_loss: 83.5865 - val_mae: 7.1902\nEpoch 15/20\n\u001b[1m 294/1006\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 211ms/step - loss: 32.9958 - mae: 4.2386","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 742/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 217ms/step - loss: 32.9968 - mae: 4.2409","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 986/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - loss: 33.0797 - mae: 4.2474","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 265ms/step - loss: 33.0849 - mae: 4.2478 - val_loss: 84.0785 - val_mae: 7.2480\nEpoch 16/20\n\u001b[1m 226/1006\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 203ms/step - loss: 29.1885 - mae: 3.9020","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 234/1006\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 203ms/step - loss: 29.2464 - mae: 3.9069","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 343/1006\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 206ms/step - loss: 29.7148 - mae: 3.9483","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 254ms/step - loss: 30.8911 - mae: 4.0505 - val_loss: 83.6305 - val_mae: 7.2554\nEpoch 17/20\n\u001b[1m 400/1006\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 204ms/step - loss: 29.7382 - mae: 3.9481","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 651/1006\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 211ms/step - loss: 30.0631 - mae: 3.9717","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 940/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 209ms/step - loss: 30.2701 - mae: 3.9876","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 258ms/step - loss: 30.3013 - mae: 3.9902 - val_loss: 84.9570 - val_mae: 7.2815\nEpoch 18/20\n\u001b[1m  41/1006\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 221ms/step - loss: 28.3762 - mae: 3.7775","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  54/1006\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:34\u001b[0m 225ms/step - loss: 28.7746 - mae: 3.8083","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 228/1006\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 210ms/step - loss: 28.9687 - mae: 3.8472","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 261ms/step - loss: 29.0336 - mae: 3.8673 - val_loss: 84.0394 - val_mae: 7.2276\nEpoch 19/20\n\u001b[1m 841/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m34s\u001b[0m 210ms/step - loss: 28.5363 - mae: 3.8135","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 845/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - loss: 28.5357 - mae: 3.8135","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 855/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m31s\u001b[0m 209ms/step - loss: 28.5341 - mae: 3.8135","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 263ms/step - loss: 28.5313 - mae: 3.8146 - val_loss: 84.2926 - val_mae: 7.2399\nEpoch 20/20\n\u001b[1m 228/1006\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 219ms/step - loss: 28.3424 - mae: 3.7742","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 458/1006\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 211ms/step - loss: 28.1067 - mae: 3.7601","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 472/1006\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 211ms/step - loss: 28.0992 - mae: 3.7598","output_type":"stream"},{"name":"stderr","text":"libpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 265ms/step - loss: 28.1211 - mae: 3.7683 - val_loss: 83.6998 - val_mae: 7.2261\nModel Training completed and saved.\n* Running on local URL:  http://127.0.0.1:7860\nIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://34a5aeecf17e5fcd0b.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://34a5aeecf17e5fcd0b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step\nExported mesh to /tmp/tmpt38a5uay/generated_mesh.obj\nError: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\nExported mesh to /tmp/tmpn7krwhgv/generated_mesh.obj\n","output_type":"stream"}],"execution_count":2}]}